% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenizer.R
\name{getFromFolderWF}
\alias{getFromFolderWF}
\title{Function which takes a folder as an argument and returns a vector
with the unique tokens for each document and their frequencies}
\usage{
getFromFolderWF(pathToFolder, minMaxWordCount = 300)
}
\arguments{
\item{pathToFolder, }{the folder containing your corpus}

\item{minMaxWordCount, }{no documents with less tokens than indicated will be accepted and all documents longer than the spefified count will be cropped Defaults to 300}
}
\description{
This function takes a path to a folder as an argument.  It then
excludes all documents in the folder which have less than 300 
tokens and process the rest.  The output is a data structure which
can be iterated through length-wise.  Odd indexes in the data structure
return lists which hold the unique tokens of an individual document,
even indexes hold the frequencies
}
\keyword{frequency,}
\keyword{sample}
\keyword{size}
\keyword{token,}
\keyword{tokenize,}
\keyword{word}

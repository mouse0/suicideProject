% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenizer.R
\name{tokenize}
\alias{tokenize}
\title{Function to tokenzie the document and calculate the frequencies of each unique token}
\usage{
tokenize(string)
}
\arguments{
\item{string, }{the string which you would like tokenized}
}
\description{
This function takes a string as an argument and returns a data frame containing the
unique tokens and their frequencies, organized so that the most frequent
ones are on top
}
\keyword{frequency,}
\keyword{token}
\keyword{tokenize,}
\keyword{word}
